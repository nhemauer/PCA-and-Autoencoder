{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f241acb-86aa-47c4-ab8a-c79ba737d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.util import random_noise\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f393295-629e-4bbe-a9d2-48064ba18fff",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d03a26-874f-425c-aa09-7c0413b1ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "image_data = pd.read_csv(\"image_data.csv\")\n",
    "\n",
    "# Compute the mean image\n",
    "mu = np.mean(image_data, axis = 0)\n",
    "\n",
    "images_centered = image_data - mu\n",
    "\n",
    "# Reshape the mean image to 28x28\n",
    "mu_image = mu.values.reshape(28, 28)\n",
    "\n",
    "# Plot the mean image\n",
    "plt.imshow(mu_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d7a93-4e20-42f7-91a5-20f75bfa8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 5 images\n",
    "for x in range(3):\n",
    "    plt.imshow(images_centered.iloc[x].values.reshape(28, 28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ec7f0-6006-40fa-8239-9495e298271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find covariance matrix\n",
    "cov_matrix = np.cov(images_centered, rowvar = False)\n",
    "\n",
    "# Find eigenvalues/eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort eigenvalues and eigenvectors in descending order\n",
    "index = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues_sort = np.real(eigenvalues[index])\n",
    "eigenvectors_sort = np.real(eigenvectors[:, index])\n",
    "\n",
    "# Plot eigen\n",
    "for i in range(3):\n",
    "    eigenvector = eigenvectors_sort[:, i].reshape(28, 28)\n",
    "    plt.imshow(eigenvector)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c75ac-0ce7-4a60-b7c5-460655d285ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector25 = eigenvectors_sort[:, :25]\n",
    "eigenvector25_norm = eigenvector25 / np.linalg.norm(eigenvector25, axis = 0)\n",
    "\n",
    "# Find z\n",
    "z = np.dot(images_centered, eigenvector25_norm)\n",
    "\n",
    "for i in range(3):\n",
    "    print(z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f49b51-9c7c-422d-8032-016f55ea4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_image_1d = mu_image.reshape(1, -1)\n",
    "\n",
    "# Reconstruct images\n",
    "reconstructed = np.dot(z, eigenvector25_norm.T) + mu_image_1d\n",
    "\n",
    "for i in range(3):\n",
    "    plt.imshow(reconstructed[i].reshape(28, 28))\n",
    "    plt.show()\n",
    "    \n",
    "for i in range(3):\n",
    "    plt.imshow(image_data.iloc[i].values.reshape(28, 28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d8e1b-2b09-48bd-9459-57eed7176501",
   "metadata": {},
   "source": [
    "# Linear Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70176f82-bcb3-4b6a-adca-9f4bee94e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim, dtype = torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim, dtype = torch.float64)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.fc(z)\n",
    "        return z\n",
    "\n",
    "# Define parameters\n",
    "input_dim = 28 * 28  # Size 28x28\n",
    "output_dim = 25\n",
    "\n",
    "# Initialize encoder and decoder\n",
    "encoder = Encoder(input_dim, output_dim)\n",
    "decoder = Decoder(output_dim, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae0b59f-869d-4c67-9832-a19c78a0d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 3\n",
    "epochs = 10\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, csv_file, transform = None):\n",
    "        self.data = pd.read_csv(csv_file, dtype = \"float64\")\n",
    "        self.transform = transform\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        self.data = scaler.fit_transform(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "csv_file = 'image_data.csv'\n",
    "\n",
    "# Data to tensors\n",
    "transform = torch.tensor\n",
    "\n",
    "# Data\n",
    "dataset = Dataset(csv_file, transform = transform)\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2638a19-b1ef-4077-b0b4-e6bb4d86fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and Loss\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr = lr)\n",
    "\n",
    "# Train\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for data in data_loader:\n",
    "        inputs = data \n",
    "        optimizer.zero_grad()\n",
    "        encoded = encoder(inputs)\n",
    "        decoded = decoder(encoded)\n",
    "        loss = criterion(decoded, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(data_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff3a58-1f0f-4d09-bd67-59731fdbdc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image function\n",
    "def imshow(image):     \n",
    "    image = image.numpy()\n",
    "    plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "images = next(iter(data_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_images = encoder(images)\n",
    "    reconstructed_images = decoder(encoded_images)\n",
    "\n",
    "# Reconstructed images\n",
    "print('Reconstructed Images:')\n",
    "imshow(torchvision.utils.make_grid(reconstructed_images.view(batch_size, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab5d3f-7a10-4d33-b585-73d570e14262",
   "metadata": {},
   "source": [
    "# Non-Linear Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3973d8e-9f94-4ce3-ad3e-887e0bde73b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128, dtype = torch.float64)  # Linear layer 1\n",
    "        self.fc2 = nn.Linear(128, output_dim, dtype = torch.float64) # Linear layer 2\n",
    "        self.relu = nn.ReLU()  # ReLU activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.relu(self.fc1(x))  # Apply ReLU activation after first linear layer\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128, dtype = torch.float64)  # Linear layer 1\n",
    "        self.fc2 = nn.Linear(128, output_dim, dtype = torch.float64) # Linear layer 2\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation function\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.fc1(z)\n",
    "        z = self.sigmoid(self.fc2(z))  # Sigmoid activation\n",
    "        return z\n",
    "\n",
    "# Parameters\n",
    "input_dim = 28 * 28  # Size 28x28\n",
    "output_dim = 25\n",
    "\n",
    "# Encoder and decoder\n",
    "encoder = Encoder(input_dim, output_dim)\n",
    "decoder = Decoder(output_dim, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a536851a-c65e-4eae-8e1b-7227846820d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 3\n",
    "epochs = 10\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, csv_file, transform = None):\n",
    "        self.data = pd.read_csv(csv_file, dtype = \"float64\")\n",
    "        self.transform = transform\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        self.data = scaler.fit_transform(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "csv_file = 'image_data.csv'\n",
    "\n",
    "# Data to tensors\n",
    "transform = torch.tensor\n",
    "\n",
    "# Data\n",
    "dataset = Dataset(csv_file, transform = transform)\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8bd448-8424-4839-99e8-a3a0f207e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and Loss\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr = lr)\n",
    "\n",
    "# Train\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for data in data_loader:\n",
    "        inputs = data \n",
    "        optimizer.zero_grad()\n",
    "        encoded = encoder(inputs)\n",
    "        decoded = decoder(encoded)\n",
    "        loss = criterion(decoded, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(data_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040bf9c9-648b-4cc9-b524-312e5222e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image function\n",
    "def imshow(image):    \n",
    "    image = image.numpy()\n",
    "    plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "images = next(iter(data_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_images = encoder(images)\n",
    "    reconstructed_images = decoder(encoded_images)\n",
    "\n",
    "# Reconstructed images\n",
    "print('Reconstructed Images:')\n",
    "imshow(torchvision.utils.make_grid(reconstructed_images.view(batch_size, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c21b1f4-56c8-4cb2-b384-9db8c1225460",
   "metadata": {},
   "source": [
    "# Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2331b-730e-43b7-80af-5f15f346767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "image_data = pd.read_csv(\"image_data.csv\").values\n",
    "\n",
    "for i in range(len(image_data)):\n",
    "    image_data[i] = random_noise(image_data[i], mode = 's&p', amount = 0.1)\n",
    "\n",
    "for i in range(3):\n",
    "    plt.imshow(image_data[i].reshape(28, 28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1ba167-36c2-43e8-97e3-135680205d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128, dtype = torch.float64)  # Linear layer 1\n",
    "        self.fc2 = nn.Linear(128, output_dim, dtype = torch.float64) # Linear layer 2\n",
    "        self.relu = nn.ReLU()  # ReLU activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.relu(self.fc1(x))  # Apply ReLU activation after first linear layer\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128, dtype = torch.float64)  # Linear layer 1\n",
    "        self.fc2 = nn.Linear(128, output_dim, dtype = torch.float64) # Linear layer 2\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation function\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.fc1(z)\n",
    "        z = self.sigmoid(self.fc2(z))  # Sigmoid activation\n",
    "        return z\n",
    "\n",
    "# Parameters\n",
    "input_dim = 28 * 28  # Size 28x28\n",
    "output_dim = 25\n",
    "\n",
    "# Encoder and decoder\n",
    "encoder = Encoder(input_dim, output_dim)\n",
    "decoder = Decoder(output_dim, input_dim)\n",
    "\n",
    "lr = 0.001\n",
    "batch_size = 3\n",
    "epochs = 10\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, csv_file, transform = None):\n",
    "        self.data = pd.read_csv(csv_file, dtype = \"float64\")\n",
    "        self.transform = transform\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        self.data = scaler.fit_transform(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "csv_file = 'image_data.csv'\n",
    "\n",
    "# Data to tensors\n",
    "transform = torch.tensor\n",
    "\n",
    "# Data\n",
    "dataset = Dataset(csv_file, transform = transform)\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# Optimizer and Loss\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr = lr)\n",
    "\n",
    "# Train\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for data in data_loader:\n",
    "        inputs = data \n",
    "        optimizer.zero_grad()\n",
    "        encoded = encoder(inputs)\n",
    "        decoded = decoder(encoded)\n",
    "        loss = criterion(decoded, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(data_loader)}\")\n",
    "    \n",
    "# Display image function\n",
    "def imshow(image):     \n",
    "    image = image.numpy()\n",
    "    plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "images = next(iter(data_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_images = encoder(images)\n",
    "    reconstructed_images = decoder(encoded_images)\n",
    "\n",
    "# Reconstructed images\n",
    "print('Reconstructed Images:')\n",
    "imshow(torchvision.utils.make_grid(reconstructed_images.view(batch_size, 1, 28, 28)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
